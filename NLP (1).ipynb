{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime as dt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize,word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'hiii priya how are you ?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hiii priya how are you ?']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hiii', 'priya', 'how', 'are', 'you', '?']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hey abu today is ur interview right']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a='hey abu today is ur interview right'\n",
    "sent_tokenize(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hey', 'abu', 'today', 'is', 'ur', 'interview', 'right']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'an apple a day keeps a doctor away'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "word_tokes = word_tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple', 'day', 'keeps', 'doctor', 'away']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comprehension list = in a list you are giving the conditions\n",
    "[w for w in word_tokes if not w in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '''this is priya\n",
    "she is very intelligent\n",
    "and brave girl'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "words = word_tokenize(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['priya', 'intelligent', 'brave', 'girl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in words if not i in stop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = '''Avul Pakir Jainulabdeen Abdul Kalam (/ˈɑːbdəl kəˈlɑːm/ (audio speaker iconlisten); 15 October 1931 – 27 July 2015) was an Indian aerospace scientist who served as the 11th president of India from 2002 to 2007. He was born and raised in Rameswaram, Tamil Nadu and studied physics and aerospace engineering. He spent the next four decades as a scientist and science administrator, mainly at the Defence Research and Development Organisation (DRDO) and Indian Space Research Organisation (ISRO) and was intimately involved in India's civilian space programme and military missile development efforts.[1] He thus came to be known as the Missile Man of India for his work on the development of ballistic missile and launch vehicle technology.[2][3][4] He also played a pivotal organisational, technical, and political role in India's Pokhran-II nuclear tests in 1998, the first since the original nuclear test by India in 1974.[5]\n",
    "\n",
    "Kalam was elected as the 11th president of India in 2002 with the support of both the ruling Bharatiya Janata Party and the then-opposition Indian National Congress. Widely referred to as the \"People's President\",[6] he returned to his civilian life of education, writing and public service after a single term. He was a recipient of several prestigious awards, including the Bharat Ratna, India's highest civilian honour.\n",
    "\n",
    "While delivering a lecture at the Indian Institute of Management Shillong, Kalam collapsed and died from an apparent cardiac arrest on 27 July 2015, aged 83.[7] Thousands, including national-level dignitaries, attended the funeral ceremony held in his hometown of Rameswaram, where he was buried with full state honours.[8]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "name = paragraph\n",
    "ps = PorterStemmer()\n",
    "words= word_tokenize(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avul\n",
      "pakir\n",
      "jainulabdeen\n",
      "abdul\n",
      "kalam\n",
      "(\n",
      "/ˈɑːbdəl\n",
      "kəˈlɑːm/\n",
      "(\n",
      "audio\n",
      "speaker\n",
      "iconlisten\n",
      ")\n",
      ";\n",
      "15\n",
      "octob\n",
      "1931\n",
      "–\n",
      "27\n",
      "juli\n",
      "2015\n",
      ")\n",
      "wa\n",
      "an\n",
      "indian\n",
      "aerospac\n",
      "scientist\n",
      "who\n",
      "serv\n",
      "as\n",
      "the\n",
      "11th\n",
      "presid\n",
      "of\n",
      "india\n",
      "from\n",
      "2002\n",
      "to\n",
      "2007\n",
      ".\n",
      "he\n",
      "wa\n",
      "born\n",
      "and\n",
      "rais\n",
      "in\n",
      "rameswaram\n",
      ",\n",
      "tamil\n",
      "nadu\n",
      "and\n",
      "studi\n",
      "physic\n",
      "and\n",
      "aerospac\n",
      "engin\n",
      ".\n",
      "he\n",
      "spent\n",
      "the\n",
      "next\n",
      "four\n",
      "decad\n",
      "as\n",
      "a\n",
      "scientist\n",
      "and\n",
      "scienc\n",
      "administr\n",
      ",\n",
      "mainli\n",
      "at\n",
      "the\n",
      "defenc\n",
      "research\n",
      "and\n",
      "develop\n",
      "organis\n",
      "(\n",
      "drdo\n",
      ")\n",
      "and\n",
      "indian\n",
      "space\n",
      "research\n",
      "organis\n",
      "(\n",
      "isro\n",
      ")\n",
      "and\n",
      "wa\n",
      "intim\n",
      "involv\n",
      "in\n",
      "india\n",
      "'s\n",
      "civilian\n",
      "space\n",
      "programm\n",
      "and\n",
      "militari\n",
      "missil\n",
      "develop\n",
      "effort\n",
      ".\n",
      "[\n",
      "1\n",
      "]\n",
      "he\n",
      "thu\n",
      "came\n",
      "to\n",
      "be\n",
      "known\n",
      "as\n",
      "the\n",
      "missil\n",
      "man\n",
      "of\n",
      "india\n",
      "for\n",
      "hi\n",
      "work\n",
      "on\n",
      "the\n",
      "develop\n",
      "of\n",
      "ballist\n",
      "missil\n",
      "and\n",
      "launch\n",
      "vehicl\n",
      "technolog\n",
      ".\n",
      "[\n",
      "2\n",
      "]\n",
      "[\n",
      "3\n",
      "]\n",
      "[\n",
      "4\n",
      "]\n",
      "he\n",
      "also\n",
      "play\n",
      "a\n",
      "pivot\n",
      "organis\n",
      ",\n",
      "technic\n",
      ",\n",
      "and\n",
      "polit\n",
      "role\n",
      "in\n",
      "india\n",
      "'s\n",
      "pokhran-ii\n",
      "nuclear\n",
      "test\n",
      "in\n",
      "1998\n",
      ",\n",
      "the\n",
      "first\n",
      "sinc\n",
      "the\n",
      "origin\n",
      "nuclear\n",
      "test\n",
      "by\n",
      "india\n",
      "in\n",
      "1974\n",
      ".\n",
      "[\n",
      "5\n",
      "]\n",
      "kalam\n",
      "wa\n",
      "elect\n",
      "as\n",
      "the\n",
      "11th\n",
      "presid\n",
      "of\n",
      "india\n",
      "in\n",
      "2002\n",
      "with\n",
      "the\n",
      "support\n",
      "of\n",
      "both\n",
      "the\n",
      "rule\n",
      "bharatiya\n",
      "janata\n",
      "parti\n",
      "and\n",
      "the\n",
      "then-opposit\n",
      "indian\n",
      "nation\n",
      "congress\n",
      ".\n",
      "wide\n",
      "refer\n",
      "to\n",
      "as\n",
      "the\n",
      "``\n",
      "peopl\n",
      "'s\n",
      "presid\n",
      "''\n",
      ",\n",
      "[\n",
      "6\n",
      "]\n",
      "he\n",
      "return\n",
      "to\n",
      "hi\n",
      "civilian\n",
      "life\n",
      "of\n",
      "educ\n",
      ",\n",
      "write\n",
      "and\n",
      "public\n",
      "servic\n",
      "after\n",
      "a\n",
      "singl\n",
      "term\n",
      ".\n",
      "he\n",
      "wa\n",
      "a\n",
      "recipi\n",
      "of\n",
      "sever\n",
      "prestigi\n",
      "award\n",
      ",\n",
      "includ\n",
      "the\n",
      "bharat\n",
      "ratna\n",
      ",\n",
      "india\n",
      "'s\n",
      "highest\n",
      "civilian\n",
      "honour\n",
      ".\n",
      "while\n",
      "deliv\n",
      "a\n",
      "lectur\n",
      "at\n",
      "the\n",
      "indian\n",
      "institut\n",
      "of\n",
      "manag\n",
      "shillong\n",
      ",\n",
      "kalam\n",
      "collaps\n",
      "and\n",
      "die\n",
      "from\n",
      "an\n",
      "appar\n",
      "cardiac\n",
      "arrest\n",
      "on\n",
      "27\n",
      "juli\n",
      "2015\n",
      ",\n",
      "age\n",
      "83\n",
      ".\n",
      "[\n",
      "7\n",
      "]\n",
      "thousand\n",
      ",\n",
      "includ\n",
      "national-level\n",
      "dignitari\n",
      ",\n",
      "attend\n",
      "the\n",
      "funer\n",
      "ceremoni\n",
      "held\n",
      "in\n",
      "hi\n",
      "hometown\n",
      "of\n",
      "rameswaram\n",
      ",\n",
      "where\n",
      "he\n",
      "wa\n",
      "buri\n",
      "with\n",
      "full\n",
      "state\n",
      "honour\n",
      ".\n",
      "[\n",
      "8\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "for w in words:\n",
    "    print(ps.stem(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lemmatizer ( POS...> parts of speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foot\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "le = WordNetLemmatizer()\n",
    "print(le.lemmatize('feet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "priya\n"
     ]
    }
   ],
   "source": [
    "print(le.lemmatize('priya'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goods\n"
     ]
    }
   ],
   "source": [
    "print(le.lemmatize('goods','v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loving\n"
     ]
    }
   ],
   "source": [
    "print(le.lemmatize('loving'))  # this is noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "live\n"
     ]
    }
   ],
   "source": [
    "print(le.lemmatize('living','v'))  # verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = '''Hii this is priya and \n",
    "I am the student of data science\n",
    "from simplilearn'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = sent_tokenize(txt)\n",
    "for i in sent:\n",
    "    words = word_tokenize(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = [w for w in words if not w in stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "tagged = nltk.pos_tag(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hii', 'NNP'),\n",
       " ('priya', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " ('student', 'VBP'),\n",
       " ('data', 'NNS'),\n",
       " ('science', 'NN'),\n",
       " ('simplilearn', 'NN')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''as a carefree street smart man \n",
    "in Race Gurram won him two more Filmfare\n",
    "Awards for Best Actor – Telugu. Allu also\n",
    "won the Filmfare Award for Best Supporting\n",
    "Actor for his portrayal of prince Gona Ganna\n",
    "Reddy in Rudhramadevi. Allu received huge acclaim\n",
    "for his performance in Pushpa: The Rise, which\n",
    "emerged as the highest-grossing Indian film in\n",
    "2021, and ranks among the highest-grossing Telugu\n",
    "films of all time.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['as a carefree street smart man \\nin Race Gurram won him two more Filmfare\\nAwards for Best Actor – Telugu.',\n",
       " 'Allu also\\nwon the Filmfare Award for Best Supporting\\nActor for his portrayal of prince Gona Ganna\\nReddy in Rudhramadevi.',\n",
       " 'Allu received huge acclaim\\nfor his performance in Pushpa: The Rise, which\\nemerged as the highest-grossing Indian film in\\n2021, and ranks among the highest-grossing Telugu\\nfilms of all time.']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = sent_tokenize(text)\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sent:\n",
    "    words = word_tokenize(i)\n",
    "    words = [w for w in words if not w in stop]\n",
    "    tagged = nltk.pos_tag(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Allu',\n",
       " 'received',\n",
       " 'huge',\n",
       " 'acclaim',\n",
       " 'performance',\n",
       " 'Pushpa',\n",
       " ':',\n",
       " 'The',\n",
       " 'Rise',\n",
       " ',',\n",
       " 'emerged',\n",
       " 'highest-grossing',\n",
       " 'Indian',\n",
       " 'film',\n",
       " '2021',\n",
       " ',',\n",
       " 'ranks',\n",
       " 'among',\n",
       " 'highest-grossing',\n",
       " 'Telugu',\n",
       " 'films',\n",
       " 'time',\n",
       " '.']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Allu', 'NNP'),\n",
       " ('received', 'VBD'),\n",
       " ('huge', 'JJ'),\n",
       " ('acclaim', 'NN'),\n",
       " ('performance', 'NN'),\n",
       " ('Pushpa', 'NNP'),\n",
       " (':', ':'),\n",
       " ('The', 'DT'),\n",
       " ('Rise', 'NNP'),\n",
       " (',', ','),\n",
       " ('emerged', 'VBD'),\n",
       " ('highest-grossing', 'JJ'),\n",
       " ('Indian', 'JJ'),\n",
       " ('film', 'NN'),\n",
       " ('2021', 'CD'),\n",
       " (',', ','),\n",
       " ('ranks', 'VBZ'),\n",
       " ('among', 'IN'),\n",
       " ('highest-grossing', 'JJ'),\n",
       " ('Telugu', 'NNP'),\n",
       " ('films', 'NNS'),\n",
       " ('time', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '''\n",
    "        text mining also referred to as text data mining,\n",
    "        roughly equivalent to text analytics, is the process of deriving high quality information from text.\n",
    "        High quality information is typically derived through the devising of patterns and trends through means \n",
    "        such as staitctical pattern learning\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = sent_tokenize(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n        text mining also referred to as text data mining,\\n        roughly equivalent to text analytics, is the process of deriving high quality information from text.',\n",
       " 'High quality information is typically derived through the devising of patterns and trends through means \\n        such as staitctical pattern learning']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sent:\n",
    "    words = word_tokenize(i)\n",
    "    tagged = nltk.pos_tag(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('High', 'JJ'),\n",
       " ('quality', 'NN'),\n",
       " ('information', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('typically', 'RB'),\n",
       " ('derived', 'VBN'),\n",
       " ('through', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('devising', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('patterns', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('trends', 'NNS'),\n",
       " ('through', 'IN'),\n",
       " ('means', 'NNS'),\n",
       " ('such', 'JJ'),\n",
       " ('as', 'IN'),\n",
       " ('staitctical', 'JJ'),\n",
       " ('pattern', 'NN'),\n",
       " ('learning', 'VBG')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamlet = nltk.corpus.gutenberg.words('shakespeare-hamlet.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37360"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hamlet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamlet_pos = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in hamlet[:3000]:\n",
    "    word_pos=nltk.pos_tag([word])\n",
    "    hamlet_pos.append(word_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('[', 'NN')],\n",
       " [('The', 'DT')],\n",
       " [('Tragedie', 'NN')],\n",
       " [('of', 'IN')],\n",
       " [('Hamlet', 'NN')],\n",
       " [('by', 'IN')],\n",
       " [('William', 'NNP')],\n",
       " [('Shakespeare', 'NN')],\n",
       " [('1599', 'CD')],\n",
       " [(']', 'NN')],\n",
       " [('Actus', 'NN')],\n",
       " [('Primus', 'NN')],\n",
       " [('.', '.')],\n",
       " [('Scoena', 'NN')],\n",
       " [('Prima', 'NN')],\n",
       " [('.', '.')],\n",
       " [('Enter', 'NN')],\n",
       " [('Barnardo', 'NN')],\n",
       " [('and', 'CC')],\n",
       " [('Francisco', 'NNP')],\n",
       " [('two', 'CD')],\n",
       " [('Centinels', 'NNS')],\n",
       " [('.', '.')],\n",
       " [('Barnardo', 'NN')],\n",
       " [('.', '.')],\n",
       " [('Who', 'WP')],\n",
       " [(\"'\", \"''\")],\n",
       " [('s', 'NN')],\n",
       " [('there', 'RB')],\n",
       " [('?', '.')],\n",
       " [('Fran', 'NN')],\n",
       " [('.', '.')],\n",
       " [('Nay', 'NN')],\n",
       " [('answer', 'NN')],\n",
       " [('me', 'PRP')],\n",
       " [(':', ':')],\n",
       " [('Stand', 'NN')],\n",
       " [('&', 'CC')],\n",
       " [('vnfold', 'NN')],\n",
       " [('your', 'PRP$')],\n",
       " [('selfe', 'NN')],\n",
       " [('Bar', 'NN')],\n",
       " [('.', '.')],\n",
       " [('Long', 'RB')],\n",
       " [('liue', 'NN')],\n",
       " [('the', 'DT')],\n",
       " [('King', 'VBG')],\n",
       " [('Fran', 'NN')],\n",
       " [('.', '.')],\n",
       " [('Barnardo', 'NN')],\n",
       " [('?', '.')],\n",
       " [('Bar', 'NN')],\n",
       " [('.', '.')],\n",
       " [('He', 'PRP')],\n",
       " [('Fran', 'NN')],\n",
       " [('.', '.')],\n",
       " [('You', 'PRP')],\n",
       " [('come', 'VB')],\n",
       " [('most', 'JJS')],\n",
       " [('carefully', 'RB')],\n",
       " [('vpon', 'NN')],\n",
       " [('your', 'PRP$')],\n",
       " [('houre', 'NN')],\n",
       " [('Bar', 'NN')],\n",
       " [('.', '.')],\n",
       " [(\"'\", \"''\")],\n",
       " [('Tis', 'NN')],\n",
       " [('now', 'RB')],\n",
       " [('strook', 'NN')],\n",
       " [('twelue', 'NN')],\n",
       " [(',', ',')],\n",
       " [('get', 'VB')],\n",
       " [('thee', 'NN')],\n",
       " [('to', 'TO')],\n",
       " [('bed', 'NN')],\n",
       " [('Francisco', 'NNP')],\n",
       " [('Fran', 'NN')],\n",
       " [('.', '.')],\n",
       " [('For', 'IN')],\n",
       " [('this', 'DT')],\n",
       " [('releefe', 'NN')],\n",
       " [('much', 'JJ')],\n",
       " [('thankes', 'NNS')],\n",
       " [(':', ':')],\n",
       " [(\"'\", \"''\")],\n",
       " [('Tis', 'NN')],\n",
       " [('bitter', 'NN')],\n",
       " [('cold', 'NN')],\n",
       " [(',', ',')],\n",
       " [('And', 'CC')],\n",
       " [('I', 'PRP')],\n",
       " [('am', 'VBP')],\n",
       " [('sicke', 'NN')],\n",
       " [('at', 'IN')],\n",
       " [('heart', 'NN')],\n",
       " [('Barn', 'NN')],\n",
       " [('.', '.')],\n",
       " [('Haue', 'NN')],\n",
       " [('you', 'PRP')],\n",
       " [('had', 'VBD')],\n",
       " [('quiet', 'JJ')],\n",
       " [('Guard', 'NN')],\n",
       " [('?', '.')],\n",
       " [('Fran', 'NN')],\n",
       " [('.', '.')],\n",
       " [('Not', 'RB')],\n",
       " [('a', 'DT')],\n",
       " [('Mouse', 'NN')],\n",
       " [('stirring', 'VBG')],\n",
       " [('Barn', 'NN')],\n",
       " [('.', '.')],\n",
       " [('Well', 'RB')],\n",
       " [(',', ',')],\n",
       " [('goodnight', 'NN')],\n",
       " [('.', '.')],\n",
       " [('If', 'IN')],\n",
       " [('you', 'PRP')],\n",
       " [('do', 'VB')],\n",
       " [('meet', 'NN')],\n",
       " [('Horatio', 'NN')],\n",
       " [('and', 'CC')],\n",
       " [('Marcellus', 'NN')],\n",
       " [(',', ',')],\n",
       " [('the', 'DT')],\n",
       " [('Riuals', 'NNS')],\n",
       " [('of', 'IN')],\n",
       " [('my', 'PRP$')],\n",
       " [('Watch', 'NN')],\n",
       " [(',', ',')],\n",
       " [('bid', 'NN')],\n",
       " [('them', 'PRP')],\n",
       " [('make', 'VB')],\n",
       " [('hast', 'NN')],\n",
       " [('.', '.')],\n",
       " [('Enter', 'NN')],\n",
       " [('Horatio', 'NN')],\n",
       " [('and', 'CC')],\n",
       " [('Marcellus', 'NN')],\n",
       " [('.', '.')],\n",
       " [('Fran', 'NN')],\n",
       " [('.', '.')],\n",
       " [('I', 'PRP')],\n",
       " [('thinke', 'NN')],\n",
       " [('I', 'PRP')],\n",
       " [('heare', 'NN')],\n",
       " [('them', 'PRP')],\n",
       " [('.', '.')],\n",
       " [('Stand', 'NN')],\n",
       " [(':', ':')],\n",
       " [('who', 'WP')],\n",
       " [(\"'\", \"''\")],\n",
       " [('s', 'NN')],\n",
       " [('there', 'RB')],\n",
       " [('?', '.')],\n",
       " [('Hor', 'NN')],\n",
       " [('.', '.')],\n",
       " [('Friends', 'NNS')],\n",
       " [('to', 'TO')],\n",
       " [('this', 'DT')],\n",
       " [('ground', 'NN')],\n",
       " [('Mar', 'NN')],\n",
       " [('.', '.')],\n",
       " [('And', 'CC')],\n",
       " [('Leige', 'NN')],\n",
       " [('-', ':')],\n",
       " [('men', 'NNS')],\n",
       " [('to', 'TO')],\n",
       " [('the', 'DT')],\n",
       " [('Dane', 'NN')],\n",
       " [('Fran', 'NN')],\n",
       " [('.', '.')],\n",
       " [('Giue', 'NN')],\n",
       " [('you', 'PRP')],\n",
       " [('good', 'JJ')],\n",
       " [('night', 'NN')],\n",
       " [('Mar', 'NN')],\n",
       " [('.', '.')],\n",
       " [('O', 'NN')],\n",
       " [('farwel', 'NN')],\n",
       " [('honest', 'NN')],\n",
       " [('Soldier', 'NN')],\n",
       " [(',', ',')],\n",
       " [('who', 'WP')],\n",
       " [('hath', 'NN')],\n",
       " [('relieu', 'NN')],\n",
       " [(\"'\", \"''\")],\n",
       " [('d', 'NN')],\n",
       " [('you', 'PRP')],\n",
       " [('?', '.')],\n",
       " [('Fra', 'NN')],\n",
       " [('.', '.')],\n",
       " [('Barnardo', 'NN')],\n",
       " [('ha', 'NN')],\n",
       " [(\"'\", \"''\")],\n",
       " [('s', 'NN')],\n",
       " [('my', 'PRP$')],\n",
       " [('place', 'NN')],\n",
       " [(':', ':')],\n",
       " [('giue', 'NN')],\n",
       " [('you', 'PRP')],\n",
       " [('goodnight', 'NN')],\n",
       " [('.', '.')],\n",
       " [('Exit', 'NN')],\n",
       " [('Fran', 'NN')],\n",
       " [('.', '.')],\n",
       " [('Mar', 'NN')],\n",
       " [('.', '.')],\n",
       " [('Holla', 'NN')],\n",
       " [('Barnardo', 'NN')],\n",
       " [('Bar', 'NN')],\n",
       " [('.', '.')],\n",
       " [('Say', 'NN')],\n",
       " [(',', ',')],\n",
       " [('what', 'WP')],\n",
       " [('is', 'VBZ')],\n",
       " [('Horatio', 'NN')],\n",
       " [('there', 'RB')],\n",
       " [('?', '.')],\n",
       " [('Hor', 'NN')],\n",
       " [('.', '.')],\n",
       " [('A', 'DT')],\n",
       " [('peece', 'NN')],\n",
       " [('of', 'IN')],\n",
       " [('him', 'PRP')],\n",
       " [('Bar', 'NN')],\n",
       " [('.', '.')],\n",
       " [('Welcome', 'VB')],\n",
       " [('Horatio', 'NN')],\n",
       " [(',', ',')],\n",
       " [('welcome', 'NN')],\n",
       " [('good', 'JJ')],\n",
       " [('Marcellus', 'NN')],\n",
       " [('Mar', 'NN')],\n",
       " [('.', '.')],\n",
       " [('What', 'WP')],\n",
       " [(',', ',')],\n",
       " [('ha', 'NN')],\n",
       " [(\"'\", \"''\")],\n",
       " [('s', 'NN')],\n",
       " [('this', 'DT')],\n",
       " [('thing', 'NN')],\n",
       " [('appear', 'VB')],\n",
       " [(\"'\", \"''\")],\n",
       " [('d', 'NN')],\n",
       " [('againe', 'NN')],\n",
       " [('to', 'TO')],\n",
       " [('night', 'NN')],\n",
       " [('Bar', 'NN')],\n",
       " [('.', '.')],\n",
       " [('I', 'PRP')],\n",
       " [('haue', 'NN')],\n",
       " [('seene', 'NN')],\n",
       " [('nothing', 'NN')],\n",
       " [('Mar', 'NN')],\n",
       " [('.', '.')],\n",
       " [('Horatio', 'NN')],\n",
       " [('saies', 'NNS')],\n",
       " [(',', ',')],\n",
       " [(\"'\", \"''\")],\n",
       " [('tis', 'NN')],\n",
       " [('but', 'CC')],\n",
       " [('our', 'PRP$')],\n",
       " [('Fantasie', 'NN')],\n",
       " [(',', ',')],\n",
       " [('And', 'CC')],\n",
       " [('will', 'MD')],\n",
       " [('not', 'RB')],\n",
       " [('let', 'VB')],\n",
       " [('beleefe', 'NN')],\n",
       " [('take', 'VB')],\n",
       " [('hold', 'NN')],\n",
       " [('of', 'IN')],\n",
       " [('him', 'PRP')],\n",
       " [('Touching', 'VBG')],\n",
       " [('this', 'DT')],\n",
       " [('dreaded', 'VBN')],\n",
       " [('sight', 'NN')],\n",
       " [(',', ',')],\n",
       " [('twice', 'RB')],\n",
       " [('seene', 'NN')],\n",
       " [('of', 'IN')],\n",
       " [('vs', 'NN')],\n",
       " [(',', ',')],\n",
       " [('Therefore', 'RB')],\n",
       " [('I', 'PRP')],\n",
       " [('haue', 'NN')],\n",
       " [('intreated', 'VBN')],\n",
       " [('him', 'PRP')],\n",
       " [('along', 'IN')],\n",
       " [('With', 'IN')],\n",
       " [('vs', 'NN')],\n",
       " [(',', ',')],\n",
       " [('to', 'TO')],\n",
       " [('watch', 'NN')],\n",
       " [('the', 'DT')],\n",
       " [('minutes', 'NNS')],\n",
       " [('of', 'IN')],\n",
       " [('this', 'DT')],\n",
       " [('Night', 'NN')],\n",
       " [(',', ',')],\n",
       " [('That', 'DT')],\n",
       " [('if', 'IN')],\n",
       " [('againe', 'NN')],\n",
       " [('this', 'DT')],\n",
       " [('Apparition', 'NN')],\n",
       " [('come', 'VB')],\n",
       " [(',', ',')],\n",
       " [('He', 'PRP')],\n",
       " [('may', 'MD')],\n",
       " [('approue', 'NN')],\n",
       " [('our', 'PRP$')],\n",
       " [('eyes', 'NNS')],\n",
       " [(',', ',')],\n",
       " [('and', 'CC')],\n",
       " [('speake', 'NN')],\n",
       " [('to', 'TO')],\n",
       " [('it', 'PRP')],\n",
       " [('Hor', 'NN')],\n",
       " [('.', '.')],\n",
       " [('Tush', 'NN')],\n",
       " [(',', ',')],\n",
       " [('tush', 'NN')],\n",
       " [(',', ',')],\n",
       " [(\"'\", \"''\")],\n",
       " [('twill', 'NN')],\n",
       " [('not', 'RB')],\n",
       " [('appeare', 'NN')],\n",
       " [('Bar', 'NN')],\n",
       " [('.', '.')],\n",
       " [('Sit', 'NN')],\n",
       " [('downe', 'NN')],\n",
       " [('a', 'DT')],\n",
       " [('-', ':')],\n",
       " [('while', 'IN')],\n",
       " [(',', ',')],\n",
       " [('And', 'CC')],\n",
       " [('let', 'VB')],\n",
       " [('vs', 'NN')],\n",
       " [('once', 'RB')],\n",
       " [('againe', 'NN')],\n",
       " [('assaile', 'NN')],\n",
       " [('your', 'PRP$')],\n",
       " [('eares', 'NNS')],\n",
       " [(',', ',')],\n",
       " [('That', 'DT')],\n",
       " [('are', 'VBP')],\n",
       " [('so', 'RB')],\n",
       " [('fortified', 'VBN')],\n",
       " [('against', 'IN')],\n",
       " [('our', 'PRP$')],\n",
       " [('Story', 'NN')],\n",
       " [(',', ',')],\n",
       " [('What', 'WP')],\n",
       " [('we', 'PRP')],\n",
       " [('two', 'CD')],\n",
       " [('Nights', 'NNS')],\n",
       " [('haue', 'NN')],\n",
       " [('seene', 'NN')],\n",
       " [('Hor', 'NN')],\n",
       " [('.', '.')],\n",
       " [('Well', 'RB')],\n",
       " [(',', ',')],\n",
       " [('sit', 'NN')],\n",
       " [('we', 'PRP')],\n",
       " [('downe', 'NN')],\n",
       " [(',', ',')],\n",
       " [('And', 'CC')],\n",
       " [('let', 'VB')],\n",
       " [('vs', 'NN')],\n",
       " [('heare', 'NN')],\n",
       " [('Barnardo', 'NN')],\n",
       " [('speake', 'NN')],\n",
       " [('of', 'IN')],\n",
       " [('this', 'DT')],\n",
       " [('Barn', 'NN')],\n",
       " [('.', '.')],\n",
       " [('Last', 'JJ')],\n",
       " [('night', 'NN')],\n",
       " [('of', 'IN')],\n",
       " [('all', 'DT')],\n",
       " [(',', ',')],\n",
       " [('When', 'WRB')],\n",
       " [('yond', 'NN')],\n",
       " [('same', 'JJ')],\n",
       " [('Starre', 'NN')],\n",
       " [('that', 'IN')],\n",
       " [(\"'\", \"''\")],\n",
       " [('s', 'NN')],\n",
       " [('Westward', 'NNP')],\n",
       " [('from', 'IN')],\n",
       " [('the', 'DT')],\n",
       " [('Pole', 'NN')],\n",
       " [('Had', 'VBD')],\n",
       " [('made', 'VBN')],\n",
       " [('his', 'PRP$')],\n",
       " [('course', 'NN')],\n",
       " [('t', 'NN')],\n",
       " [(\"'\", \"''\")],\n",
       " [('illume', 'NN')],\n",
       " [('that', 'IN')],\n",
       " [('part', 'NN')],\n",
       " [('of', 'IN')],\n",
       " [('Heauen', 'NN')],\n",
       " [('Where', 'WRB')],\n",
       " [('now', 'RB')],\n",
       " [('it', 'PRP')],\n",
       " [('burnes', 'NNS')],\n",
       " [(',', ',')],\n",
       " [('Marcellus', 'NN')],\n",
       " [('and', 'CC')],\n",
       " [('my', 'PRP$')],\n",
       " [('selfe', 'NN')],\n",
       " [(',', ',')],\n",
       " [('The', 'DT')],\n",
       " [('Bell', 'NNP')],\n",
       " [('then', 'RB')],\n",
       " [('beating', 'NN')],\n",
       " [('one', 'CD')],\n",
       " [('Mar', 'NN')],\n",
       " [('.', '.')],\n",
       " [('Peace', 'NN')],\n",
       " [(',', ',')],\n",
       " [('breake', 'NN')],\n",
       " [('thee', 'NN')],\n",
       " [('of', 'IN')],\n",
       " [(':', ':')],\n",
       " [('Enter', 'NN')],\n",
       " [('the', 'DT')],\n",
       " [('Ghost', 'NN')],\n",
       " [('.', '.')],\n",
       " [('Looke', 'NN')],\n",
       " [('where', 'WRB')],\n",
       " [('it', 'PRP')],\n",
       " [('comes', 'VBZ')],\n",
       " [('againe', 'NN')],\n",
       " [('Barn', 'NN')],\n",
       " [('.', '.')],\n",
       " [('In', 'IN')],\n",
       " [('the', 'DT')],\n",
       " [('same', 'JJ')],\n",
       " [('figure', 'NN')],\n",
       " [(',', ',')],\n",
       " [('like', 'IN')],\n",
       " [('the', 'DT')],\n",
       " [('King', 'VBG')],\n",
       " [('that', 'IN')],\n",
       " [(\"'\", \"''\")],\n",
       " [('s', 'NN')],\n",
       " [('dead', 'JJ')],\n",
       " [('Mar', 'NN')],\n",
       " [('.', '.')],\n",
       " [('Thou', 'NN')],\n",
       " [('art', 'NN')],\n",
       " [('a', 'DT')],\n",
       " [('Scholler', 'NN')],\n",
       " [(';', ':')],\n",
       " [('speake', 'NN')],\n",
       " [('to', 'TO')],\n",
       " [('it', 'PRP')],\n",
       " [('Horatio', 'NN')],\n",
       " [('Barn', 'NN')],\n",
       " [('.', '.')],\n",
       " [('Lookes', 'NNS')],\n",
       " [('it', 'PRP')],\n",
       " [('not', 'RB')],\n",
       " [('like', 'IN')],\n",
       " [('the', 'DT')],\n",
       " [('King', 'VBG')],\n",
       " [('?', '.')],\n",
       " [('Marke', 'NN')],\n",
       " [('it', 'PRP')],\n",
       " [('Horatio', 'NN')],\n",
       " [('Hora', 'NNS')],\n",
       " [('.', '.')],\n",
       " [('Most', 'JJS')],\n",
       " [('like', 'IN')],\n",
       " [(':', ':')],\n",
       " [('It', 'PRP')],\n",
       " [('harrowes', 'NN')],\n",
       " [('me', 'PRP')],\n",
       " [('with', 'IN')],\n",
       " [('fear', 'NN')],\n",
       " [('&', 'CC')],\n",
       " [('wonder', 'NN')],\n",
       " [('Barn', 'NN')],\n",
       " [('.', '.')],\n",
       " [('It', 'PRP')],\n",
       " [('would', 'MD')],\n",
       " [('be', 'VB')],\n",
       " [('spoke', 'NN')],\n",
       " [('too', 'RB')],\n",
       " [('Mar', 'NN')],\n",
       " [('.', '.')],\n",
       " [('Question', 'NN')],\n",
       " [('it', 'PRP')],\n",
       " [('Horatio', 'NN')],\n",
       " [('Hor', 'NN')],\n",
       " [('.', '.')],\n",
       " [('What', 'WP')],\n",
       " [('art', 'NN')],\n",
       " [('thou', 'NN')],\n",
       " [('that', 'IN')],\n",
       " [('vsurp', 'NN')],\n",
       " [(\"'\", \"''\")],\n",
       " [('st', 'NN')],\n",
       " [('this', 'DT')],\n",
       " [('time', 'NN')],\n",
       " [('of', 'IN')],\n",
       " [('night', 'NN')],\n",
       " [(',', ',')],\n",
       " [('Together', 'RB')],\n",
       " [('with', 'IN')],\n",
       " [('that', 'IN')],\n",
       " [('Faire', 'NN')],\n",
       " [('and', 'CC')],\n",
       " [('Warlike', 'IN')],\n",
       " [('forme', 'NN')],\n",
       " [('In', 'IN')],\n",
       " [('which', 'WDT')],\n",
       " [('the', 'DT')],\n",
       " [('Maiesty', 'NN')],\n",
       " [('of', 'IN')],\n",
       " [('buried', 'VBN')],\n",
       " [('Denmarke', 'NN')],\n",
       " [('Did', 'NN')],\n",
       " [('sometimes', 'RB')],\n",
       " [('march', 'NN')],\n",
       " [(':', ':')],\n",
       " [('By', 'IN')],\n",
       " [('Heauen', 'NN')],\n",
       " [('I', 'PRP')],\n",
       " [('charge', 'NN')],\n",
       " [('thee', 'NN')],\n",
       " [('speake', 'NN')],\n",
       " [('Mar', 'NN')],\n",
       " [('.', '.')],\n",
       " [('It', 'PRP')],\n",
       " [('is', 'VBZ')],\n",
       " [('offended', 'VBN')],\n",
       " [('Barn', 'NN')],\n",
       " [('.', '.')],\n",
       " [('See', 'VB')],\n",
       " [(',', ',')],\n",
       " [('it', 'PRP')],\n",
       " [('stalkes', 'NNS')],\n",
       " [('away', 'RB')],\n",
       " [('Hor', 'NN')],\n",
       " [('.', '.')],\n",
       " [('Stay', 'NN')],\n",
       " [(':', ':')],\n",
       " [('speake', 'NN')],\n",
       " [(';', ':')],\n",
       " [('speake', 'NN')],\n",
       " [(':', ':')],\n",
       " [('I', 'PRP')],\n",
       " [('Charge', 'NN')],\n",
       " [('thee', 'NN')],\n",
       " [(',', ',')],\n",
       " [('speake', 'NN')],\n",
       " [('.', '.')],\n",
       " [('Exit', 'NN')],\n",
       " [('the', 'DT')],\n",
       " [('Ghost', 'NN')],\n",
       " [('.', '.')],\n",
       " [('Mar', 'NN')],\n",
       " [('.', '.')],\n",
       " [(\"'\", \"''\")],\n",
       " [('Tis', 'NN')],\n",
       " [('gone', 'VBN')],\n",
       " [(',', ',')],\n",
       " [('and', 'CC')],\n",
       " [('will', 'MD')],\n",
       " [('not', 'RB')],\n",
       " [('answer', 'NN')],\n",
       " [('Barn', 'NN')],\n",
       " [('.', '.')],\n",
       " [('How', 'WRB')],\n",
       " [('now', 'RB')],\n",
       " [('Horatio', 'NN')],\n",
       " [('?', '.')],\n",
       " [('You', 'PRP')],\n",
       " [('tremble', 'JJ')],\n",
       " [('&', 'CC')],\n",
       " [('look', 'NN')],\n",
       " [('pale', 'NN')],\n",
       " [(':', ':')],\n",
       " [('Is', 'NN')],\n",
       " [('not', 'RB')],\n",
       " [('this', 'DT')],\n",
       " [('something', 'NN')],\n",
       " [('more', 'RBR')],\n",
       " [('then', 'RB')],\n",
       " [('Fantasie', 'NN')],\n",
       " [('?', '.')],\n",
       " [('What', 'WP')],\n",
       " [('thinke', 'NN')],\n",
       " [('you', 'PRP')],\n",
       " [('on', 'IN')],\n",
       " [(\"'\", \"''\")],\n",
       " [('t', 'NN')],\n",
       " [('?', '.')],\n",
       " [('Hor', 'NN')],\n",
       " [('.', '.')],\n",
       " [('Before', 'IN')],\n",
       " [('my', 'PRP$')],\n",
       " [('God', 'NNP')],\n",
       " [(',', ',')],\n",
       " [('I', 'PRP')],\n",
       " [('might', 'MD')],\n",
       " [('not', 'RB')],\n",
       " [('this', 'DT')],\n",
       " [('beleeue', 'NN')],\n",
       " [('Without', 'IN')],\n",
       " [('the', 'DT')],\n",
       " [('sensible', 'JJ')],\n",
       " [('and', 'CC')],\n",
       " [('true', 'JJ')],\n",
       " [('auouch', 'JJ')],\n",
       " [('Of', 'IN')],\n",
       " [('mine', 'NN')],\n",
       " [('owne', 'NN')],\n",
       " [('eyes', 'NNS')],\n",
       " [('Mar', 'NN')],\n",
       " [('.', '.')],\n",
       " [('Is', 'NN')],\n",
       " [('it', 'PRP')],\n",
       " [('not', 'RB')],\n",
       " [('like', 'IN')],\n",
       " [('the', 'DT')],\n",
       " [('King', 'VBG')],\n",
       " [('?', '.')],\n",
       " [('Hor', 'NN')],\n",
       " [('.', '.')],\n",
       " [('As', 'IN')],\n",
       " [('thou', 'NN')],\n",
       " [('art', 'NN')],\n",
       " [('to', 'TO')],\n",
       " [('thy', 'NN')],\n",
       " [('selfe', 'NN')],\n",
       " [(',', ',')],\n",
       " [('Such', 'JJ')],\n",
       " [('was', 'VBD')],\n",
       " [('the', 'DT')],\n",
       " [('very', 'RB')],\n",
       " [('Armour', 'NN')],\n",
       " [('he', 'PRP')],\n",
       " [('had', 'VBD')],\n",
       " [('on', 'IN')],\n",
       " [(',', ',')],\n",
       " [('When', 'WRB')],\n",
       " [('th', 'NN')],\n",
       " [(\"'\", \"''\")],\n",
       " [('Ambitious', 'JJ')],\n",
       " [('Norwey', 'NN')],\n",
       " [('combatted', 'VBN')],\n",
       " [(':', ':')],\n",
       " [('So', 'RB')],\n",
       " [('frown', 'NN')],\n",
       " [(\"'\", \"''\")],\n",
       " [('d', 'NN')],\n",
       " [('he', 'PRP')],\n",
       " [('once', 'RB')],\n",
       " [(',', ',')],\n",
       " [('when', 'WRB')],\n",
       " [('in', 'IN')],\n",
       " [('an', 'DT')],\n",
       " [('angry', 'JJ')],\n",
       " [('parle', 'NN')],\n",
       " [('He', 'PRP')],\n",
       " [('smot', 'NN')],\n",
       " [('the', 'DT')],\n",
       " [('sledded', 'VBD')],\n",
       " [('Pollax', 'NN')],\n",
       " [('on', 'IN')],\n",
       " [('the', 'DT')],\n",
       " [('Ice', 'NN')],\n",
       " [('.', '.')],\n",
       " [(\"'\", \"''\")],\n",
       " [('Tis', 'NN')],\n",
       " [('strange', 'NN')],\n",
       " [('Mar', 'NN')],\n",
       " [('.', '.')],\n",
       " [('Thus', 'RB')],\n",
       " [('twice', 'RB')],\n",
       " [('before', 'IN')],\n",
       " [(',', ',')],\n",
       " [('and', 'CC')],\n",
       " [('iust', 'NN')],\n",
       " [('at', 'IN')],\n",
       " [('this', 'DT')],\n",
       " [('dead', 'JJ')],\n",
       " [('houre', 'NN')],\n",
       " [(',', ',')],\n",
       " [('With', 'IN')],\n",
       " [('Martiall', 'NN')],\n",
       " [('stalke', 'NN')],\n",
       " [(',', ',')],\n",
       " [('hath', 'NN')],\n",
       " [('he', 'PRP')],\n",
       " [('gone', 'VBN')],\n",
       " [('by', 'IN')],\n",
       " [('our', 'PRP$')],\n",
       " [('Watch', 'NN')],\n",
       " [('Hor', 'NN')],\n",
       " [('.', '.')],\n",
       " [('In', 'IN')],\n",
       " [('what', 'WP')],\n",
       " [('particular', 'JJ')],\n",
       " [('thought', 'NN')],\n",
       " [('to', 'TO')],\n",
       " [('work', 'NN')],\n",
       " [(',', ',')],\n",
       " [('I', 'PRP')],\n",
       " [('know', 'VB')],\n",
       " [('not', 'RB')],\n",
       " [(':', ':')],\n",
       " [('But', 'CC')],\n",
       " [('in', 'IN')],\n",
       " [('the', 'DT')],\n",
       " [('grosse', 'NN')],\n",
       " [('and', 'CC')],\n",
       " [('scope', 'NN')],\n",
       " [('of', 'IN')],\n",
       " [('my', 'PRP$')],\n",
       " [('Opinion', 'NN')],\n",
       " [(',', ',')],\n",
       " [('This', 'DT')],\n",
       " [('boades', 'NNS')],\n",
       " [('some', 'DT')],\n",
       " [('strange', 'NN')],\n",
       " [('erruption', 'NN')],\n",
       " [('to', 'TO')],\n",
       " [('our', 'PRP$')],\n",
       " [('State', 'NN')],\n",
       " [('Mar', 'NN')],\n",
       " [('.', '.')],\n",
       " [('Good', 'JJ')],\n",
       " [('now', 'RB')],\n",
       " [('sit', 'NN')],\n",
       " [('downe', 'NN')],\n",
       " [(',', ',')],\n",
       " [('&', 'CC')],\n",
       " [('tell', 'NN')],\n",
       " [('me', 'PRP')],\n",
       " [('he', 'PRP')],\n",
       " [('that', 'IN')],\n",
       " [('knowes', 'NN')],\n",
       " [('Why', 'WRB')],\n",
       " [('this', 'DT')],\n",
       " [('same', 'JJ')],\n",
       " [('strict', 'NN')],\n",
       " [('and', 'CC')],\n",
       " [('most', 'JJS')],\n",
       " [('obseruant', 'NN')],\n",
       " [('Watch', 'NN')],\n",
       " [(',', ',')],\n",
       " [('So', 'RB')],\n",
       " [('nightly', 'RB')],\n",
       " [('toyles', 'NNS')],\n",
       " [('the', 'DT')],\n",
       " [('subiect', 'NN')],\n",
       " [('of', 'IN')],\n",
       " [('the', 'DT')],\n",
       " [('Land', 'NN')],\n",
       " [(',', ',')],\n",
       " [('And', 'CC')],\n",
       " [('why', 'WRB')],\n",
       " [('such', 'JJ')],\n",
       " [('dayly', 'NN')],\n",
       " [('Cast', 'NN')],\n",
       " [('of', 'IN')],\n",
       " [('Brazon', 'NN')],\n",
       " [('Cannon', 'NN')],\n",
       " [('And', 'CC')],\n",
       " [('Forraigne', 'NN')],\n",
       " [('Mart', 'NNP')],\n",
       " [('for', 'IN')],\n",
       " [('Implements', 'NNS')],\n",
       " [('of', 'IN')],\n",
       " [('warre', 'NN')],\n",
       " [(':', ':')],\n",
       " [('Why', 'WRB')],\n",
       " [('such', 'JJ')],\n",
       " [('impresse', 'NN')],\n",
       " [('of', 'IN')],\n",
       " [('Ship', 'NN')],\n",
       " [('-', ':')],\n",
       " [('wrights', 'NNS')],\n",
       " [(',', ',')],\n",
       " [('whose', 'WP$')],\n",
       " [('sore', 'NN')],\n",
       " [('Taske', 'NN')],\n",
       " [('Do', 'VB')],\n",
       " [(\"'\", \"''\")],\n",
       " [('s', 'NN')],\n",
       " [('not', 'RB')],\n",
       " [('diuide', 'NN')],\n",
       " [('the', 'DT')],\n",
       " [('Sunday', 'NNP')],\n",
       " [('from', 'IN')],\n",
       " [('the', 'DT')],\n",
       " [('weeke', 'NN')],\n",
       " [(',', ',')],\n",
       " [('What', 'WP')],\n",
       " [('might', 'MD')],\n",
       " [('be', 'VB')],\n",
       " [('toward', 'IN')],\n",
       " [(',', ',')],\n",
       " [('that', 'IN')],\n",
       " [('this', 'DT')],\n",
       " [('sweaty', 'NN')],\n",
       " [('hast', 'NN')],\n",
       " [('Doth', 'NNP')],\n",
       " [('make', 'VB')],\n",
       " [('the', 'DT')],\n",
       " [('Night', 'NN')],\n",
       " [('ioynt', 'NN')],\n",
       " [('-', ':')],\n",
       " [('Labourer', 'NN')],\n",
       " [('with', 'IN')],\n",
       " [('the', 'DT')],\n",
       " [('day', 'NN')],\n",
       " [(':', ':')],\n",
       " [('Who', 'WP')],\n",
       " [('is', 'VBZ')],\n",
       " [(\"'\", \"''\")],\n",
       " [('t', 'NN')],\n",
       " [('that', 'IN')],\n",
       " [('can', 'MD')],\n",
       " [('informe', 'NN')],\n",
       " [('me', 'PRP')],\n",
       " [('?', '.')],\n",
       " [('Hor', 'NN')],\n",
       " [('.', '.')],\n",
       " [('That', 'DT')],\n",
       " [('can', 'MD')],\n",
       " [('I', 'PRP')],\n",
       " [(',', ',')],\n",
       " [('At', 'IN')],\n",
       " [('least', 'JJS')],\n",
       " [('the', 'DT')],\n",
       " [('whisper', 'NN')],\n",
       " [('goes', 'VBZ')],\n",
       " [('so', 'RB')],\n",
       " [(':', ':')],\n",
       " [('Our', 'PRP$')],\n",
       " [('last', 'JJ')],\n",
       " [('King', 'VBG')],\n",
       " [(',', ',')],\n",
       " [('Whose', 'VB')],\n",
       " [('Image', 'NN')],\n",
       " [('euen', 'NN')],\n",
       " [('but', 'CC')],\n",
       " [('now', 'RB')],\n",
       " [('appear', 'VB')],\n",
       " [(\"'\", \"''\")],\n",
       " [('d', 'NN')],\n",
       " [('to', 'TO')],\n",
       " [('vs', 'NN')],\n",
       " [(',', ',')],\n",
       " [('Was', 'NN')],\n",
       " [('(', '(')],\n",
       " [('as', 'IN')],\n",
       " [('you', 'PRP')],\n",
       " [('know', 'VB')],\n",
       " [(')', ')')],\n",
       " [('by', 'IN')],\n",
       " [('Fortinbras', 'NNS')],\n",
       " [('of', 'IN')],\n",
       " [('Norway', 'RB')],\n",
       " [(',', ',')],\n",
       " [('(', '(')],\n",
       " [('Thereto', 'NN')],\n",
       " [('prick', 'NN')],\n",
       " [(\"'\", \"''\")],\n",
       " [('d', 'NN')],\n",
       " [('on', 'IN')],\n",
       " [('by', 'IN')],\n",
       " [('a', 'DT')],\n",
       " [('most', 'JJS')],\n",
       " [('emulate', 'NN')],\n",
       " [('Pride', 'NN')],\n",
       " [(')', ')')],\n",
       " [('Dar', 'NN')],\n",
       " [(\"'\", \"''\")],\n",
       " [('d', 'NN')],\n",
       " [('to', 'TO')],\n",
       " [('the', 'DT')],\n",
       " [('Combate', 'NN')],\n",
       " [('.', '.')],\n",
       " [('In', 'IN')],\n",
       " [('which', 'WDT')],\n",
       " [(',', ',')],\n",
       " [('our', 'PRP$')],\n",
       " [('Valiant', 'NN')],\n",
       " [('Hamlet', 'NN')],\n",
       " [(',', ',')],\n",
       " [('(', '(')],\n",
       " [('For', 'IN')],\n",
       " [('so', 'RB')],\n",
       " [('this', 'DT')],\n",
       " [('side', 'NN')],\n",
       " [('of', 'IN')],\n",
       " [('our', 'PRP$')],\n",
       " [('knowne', 'NN')],\n",
       " [('world', 'NN')],\n",
       " [('esteem', 'NN')],\n",
       " [(\"'\", \"''\")],\n",
       " [('d', 'NN')],\n",
       " [('him', 'PRP')],\n",
       " [(')', ')')],\n",
       " [('Did', 'NN')],\n",
       " [('slay', 'NN')],\n",
       " [('this', 'DT')],\n",
       " [('Fortinbras', 'NNS')],\n",
       " [(':', ':')],\n",
       " [('who', 'WP')],\n",
       " [('by', 'IN')],\n",
       " [('a', 'DT')],\n",
       " [('Seal', 'NN')],\n",
       " [(\"'\", \"''\")],\n",
       " [('d', 'NN')],\n",
       " [('Compact', 'JJ')],\n",
       " [(',', ',')],\n",
       " [('Well', 'RB')],\n",
       " [('ratified', 'VBN')],\n",
       " [('by', 'IN')],\n",
       " [('Law', 'NN')],\n",
       " [(',', ',')],\n",
       " [('and', 'CC')],\n",
       " [('Heraldrie', 'NN')],\n",
       " [(',', ',')],\n",
       " [('Did', 'NN')],\n",
       " [('forfeite', 'NN')],\n",
       " [('(', '(')],\n",
       " [('with', 'IN')],\n",
       " [('his', 'PRP$')],\n",
       " [('life', 'NN')],\n",
       " [(')', ')')],\n",
       " [('all', 'DT')],\n",
       " [('those', 'DT')],\n",
       " [('his', 'PRP$')],\n",
       " [('Lands', 'NNS')],\n",
       " [('Which', 'WDT')],\n",
       " [('he', 'PRP')],\n",
       " [('stood', 'NN')],\n",
       " [('seiz', 'NN')],\n",
       " [(\"'\", \"''\")],\n",
       " [('d', 'NN')],\n",
       " [('on', 'IN')],\n",
       " [(',', ',')],\n",
       " [('to', 'TO')],\n",
       " [('the', 'DT')],\n",
       " [('Conqueror', 'NN')],\n",
       " [(':', ':')],\n",
       " [('Against', 'IN')],\n",
       " [('the', 'DT')],\n",
       " [('which', 'WDT')],\n",
       " [(',', ',')],\n",
       " [('a', 'DT')],\n",
       " [('Moity', 'NN')],\n",
       " [('competent', 'NN')],\n",
       " [('Was', 'NN')],\n",
       " [('gaged', 'VBN')],\n",
       " [('by', 'IN')],\n",
       " [('our', 'PRP$')],\n",
       " [('King', 'VBG')],\n",
       " [(':', ':')],\n",
       " [('which', 'WDT')],\n",
       " [('had', 'VBD')],\n",
       " [('return', 'NN')],\n",
       " [(\"'\", \"''\")],\n",
       " [('d', 'NN')],\n",
       " [('To', 'TO')],\n",
       " [('the', 'DT')],\n",
       " [('Inheritance', 'NN')],\n",
       " [('of', 'IN')],\n",
       " [('Fortinbras', 'NNS')],\n",
       " [(',', ',')],\n",
       " [('Had', 'VBD')],\n",
       " [('he', 'PRP')],\n",
       " [('bin', 'NN')],\n",
       " [('Vanquisher', 'NN')],\n",
       " [(',', ',')],\n",
       " [('as', 'IN')],\n",
       " [('by', 'IN')],\n",
       " [('the', 'DT')],\n",
       " [('same', 'JJ')],\n",
       " [('Cou', 'NN')],\n",
       " [(\"'\", \"''\")],\n",
       " [('nant', 'NN')],\n",
       " [('And', 'CC')],\n",
       " [('carriage', 'NN')],\n",
       " [('of', 'IN')],\n",
       " [('the', 'DT')],\n",
       " [('Article', 'NN')],\n",
       " [('designe', 'NN')],\n",
       " [(',', ',')],\n",
       " [('His', 'PRP$')],\n",
       " [('fell', 'VBD')],\n",
       " ...]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamlet_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ['Priya','priya','Abutorab','abutorab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Priya', 'NN')]\n",
      "[('priya', 'NN')]\n",
      "[('Abutorab', 'NN')]\n",
      "[('abutorab', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "for i in name:\n",
    "    print(nltk.pos_tag([i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'Priya is your name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = word_tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Priya', 'NN')]\n",
      "[('is', 'VBZ')]\n",
      "[('your', 'PRP$')]\n",
      "[('name', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "for i in word:\n",
    "    print(nltk.pos_tag([i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = '''Born on 15th October 1931 at Rameswaram in Tamil Nadu, \n",
    "Dr. Avul Pakir Jainulabdeen Abdul Kalam, specialized in Aeronautical \n",
    "Engineering from Madras Institute of Technology. Dr. Kalam made\n",
    "significant contribution as Project Director to develop India's \n",
    "first indigenous Satellite Launch Vehicle (SLV-III) which successfully \n",
    "injected the Rohini satellite in the near earth orbit in July 1980 and \n",
    "made India an exclusive member of Space Club. He was responsible for the\n",
    "evolution of ISRO's launch vehicle programme, particularly the PSLV \n",
    "configuration. After working for two decades in ISRO and mastering \n",
    "launch vehicle technologies, Dr. Kalam took up the responsibility \n",
    "of developing Indigenous Guided Missiles at Defence Research and \n",
    "Development Organisation as the Chief Executive of Integrated Guided\n",
    "Missile Development Programme (IGMDP). He was responsible for the development \n",
    "and operationalisation of AGNI and PRITHVI Missiles and for building indigenous\n",
    "capability in critical technologies through networking of multiple institutions. \n",
    "He was the Scientific Adviser to Defence Minister and Secretary, Department of'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Born on 15th October 1931 at Rameswaram in Tamil Nadu, \\nDr. Avul Pakir Jainulabdeen Abdul Kalam, specialized in Aeronautical \\nEngineering from Madras Institute of Technology.',\n",
       " \"Dr. Kalam made\\nsignificant contribution as Project Director to develop India's \\nfirst indigenous Satellite Launch Vehicle (SLV-III) which successfully \\ninjected the Rohini satellite in the near earth orbit in July 1980 and \\nmade India an exclusive member of Space Club.\",\n",
       " \"He was responsible for the\\nevolution of ISRO's launch vehicle programme, particularly the PSLV \\nconfiguration.\",\n",
       " 'After working for two decades in ISRO and mastering \\nlaunch vehicle technologies, Dr. Kalam took up the responsibility \\nof developing Indigenous Guided Missiles at Defence Research and \\nDevelopment Organisation as the Chief Executive of Integrated Guided\\nMissile Development Programme (IGMDP).',\n",
       " 'He was responsible for the development \\nand operationalisation of AGNI and PRITHVI Missiles and for building indigenous\\ncapability in critical technologies through networking of multiple institutions.',\n",
       " 'He was the Scientific Adviser to Defence Minister and Secretary, Department of']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Born', 'on', '15th', 'October', '1931', 'at', 'Rameswaram', 'in', 'Tamil', 'Nadu', ',', 'Dr.', 'Avul', 'Pakir', 'Jainulabdeen', 'Abdul', 'Kalam', ',', 'specialized', 'in', 'Aeronautical', 'Engineering', 'from', 'Madras', 'Institute', 'of', 'Technology', '.']\n",
      "['Dr.', 'Kalam', 'made', 'significant', 'contribution', 'as', 'Project', 'Director', 'to', 'develop', 'India', \"'s\", 'first', 'indigenous', 'Satellite', 'Launch', 'Vehicle', '(', 'SLV-III', ')', 'which', 'successfully', 'injected', 'the', 'Rohini', 'satellite', 'in', 'the', 'near', 'earth', 'orbit', 'in', 'July', '1980', 'and', 'made', 'India', 'an', 'exclusive', 'member', 'of', 'Space', 'Club', '.']\n",
      "['He', 'was', 'responsible', 'for', 'the', 'evolution', 'of', 'ISRO', \"'s\", 'launch', 'vehicle', 'programme', ',', 'particularly', 'the', 'PSLV', 'configuration', '.']\n",
      "['After', 'working', 'for', 'two', 'decades', 'in', 'ISRO', 'and', 'mastering', 'launch', 'vehicle', 'technologies', ',', 'Dr.', 'Kalam', 'took', 'up', 'the', 'responsibility', 'of', 'developing', 'Indigenous', 'Guided', 'Missiles', 'at', 'Defence', 'Research', 'and', 'Development', 'Organisation', 'as', 'the', 'Chief', 'Executive', 'of', 'Integrated', 'Guided', 'Missile', 'Development', 'Programme', '(', 'IGMDP', ')', '.']\n",
      "['He', 'was', 'responsible', 'for', 'the', 'development', 'and', 'operationalisation', 'of', 'AGNI', 'and', 'PRITHVI', 'Missiles', 'and', 'for', 'building', 'indigenous', 'capability', 'in', 'critical', 'technologies', 'through', 'networking', 'of', 'multiple', 'institutions', '.']\n",
      "['He', 'was', 'the', 'Scientific', 'Adviser', 'to', 'Defence', 'Minister', 'and', 'Secretary', ',', 'Department', 'of']\n"
     ]
    }
   ],
   "source": [
    "for sent in sent_tokenize(doc):\n",
    "    print(word_tokenize(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords_en = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['born', 'on', '15th', 'october', '1931', 'at', 'rameswaram', 'in', 'tamil', 'nadu', ',', 'dr.', 'avul', 'pakir', 'jainulabdeen', 'abdul', 'kalam', ',', 'specialized', 'in', 'aeronautical', 'engineering', 'from', 'madras', 'institute', 'of', 'technology', '.', 'dr.', 'kalam', 'made', 'significant', 'contribution', 'as', 'project', 'director', 'to', 'develop', 'india', \"'s\", 'first', 'indigenous', 'satellite', 'launch', 'vehicle', '(', 'slv-iii', ')', 'which', 'successfully', 'injected', 'the', 'rohini', 'satellite', 'in', 'the', 'near', 'earth', 'orbit', 'in', 'july', '1980', 'and', 'made', 'india', 'an', 'exclusive', 'member', 'of', 'space', 'club', '.', 'he', 'was', 'responsible', 'for', 'the', 'evolution', 'of', 'isro', \"'s\", 'launch', 'vehicle', 'programme', ',', 'particularly', 'the', 'pslv', 'configuration', '.', 'after', 'working', 'for', 'two', 'decades', 'in', 'isro', 'and', 'mastering', 'launch', 'vehicle', 'technologies', ',', 'dr.', 'kalam', 'took', 'up', 'the', 'responsibility', 'of', 'developing', 'indigenous', 'guided', 'missiles', 'at', 'defence', 'research', 'and', 'development', 'organisation', 'as', 'the', 'chief', 'executive', 'of', 'integrated', 'guided', 'missile', 'development', 'programme', '(', 'igmdp', ')', '.', 'he', 'was', 'responsible', 'for', 'the', 'development', 'and', 'operationalisation', 'of', 'agni', 'and', 'prithvi', 'missiles', 'and', 'for', 'building', 'indigenous', 'capability', 'in', 'critical', 'technologies', 'through', 'networking', 'of', 'multiple', 'institutions', '.', 'he', 'was', 'the', 'scientific', 'adviser', 'to', 'defence', 'minister', 'and', 'secretary', ',', 'department', 'of']\n"
     ]
    }
   ],
   "source": [
    "# Treat the multiple sentences as one document (no need to sent_tokenize)\n",
    "# Tokenize and lowercase\n",
    "single_tokenized_lowered = list(map(str.lower, word_tokenize(doc)))\n",
    "print(single_tokenized_lowered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['born', '15th', 'october', '1931', 'rameswaram', 'tamil', 'nadu', ',', 'dr.', 'avul', 'pakir', 'jainulabdeen', 'abdul', 'kalam', ',', 'specialized', 'aeronautical', 'engineering', 'madras', 'institute', 'technology', '.', 'dr.', 'kalam', 'made', 'significant', 'contribution', 'project', 'director', 'develop', 'india', \"'s\", 'first', 'indigenous', 'satellite', 'launch', 'vehicle', '(', 'slv-iii', ')', 'successfully', 'injected', 'rohini', 'satellite', 'near', 'earth', 'orbit', 'july', '1980', 'made', 'india', 'exclusive', 'member', 'space', 'club', '.', 'responsible', 'evolution', 'isro', \"'s\", 'launch', 'vehicle', 'programme', ',', 'particularly', 'pslv', 'configuration', '.', 'working', 'two', 'decades', 'isro', 'mastering', 'launch', 'vehicle', 'technologies', ',', 'dr.', 'kalam', 'took', 'responsibility', 'developing', 'indigenous', 'guided', 'missiles', 'defence', 'research', 'development', 'organisation', 'chief', 'executive', 'integrated', 'guided', 'missile', 'development', 'programme', '(', 'igmdp', ')', '.', 'responsible', 'development', 'operationalisation', 'agni', 'prithvi', 'missiles', 'building', 'indigenous', 'capability', 'critical', 'technologies', 'networking', 'multiple', 'institutions', '.', 'scientific', 'adviser', 'defence', 'minister', 'secretary', ',', 'department']\n"
     ]
    }
   ],
   "source": [
    "stopwords_en = set(stopwords.words('english')) # Set checking is faster in Python than list.\n",
    "\n",
    "# List comprehension.\n",
    "print([word for word in single_tokenized_lowered if word not in stopwords_en])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From string.punctuation: <class 'str'> !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "from string import punctuation\n",
    "# It's a string so you have to them into a set type\n",
    "print('From string.punctuation:', type(punctuation), punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'where', \"couldn't\", '-', 'on', 'ourselves', '(', 'mightn', \"you'd\", 'nor', 'while', 'into', 'down', 'he', 'why', 'until', \"hadn't\", \"you'll\", 'was', '}', 'own', 'aren', '~', 'be', 'or', 'against', '|', 'under', 'hadn', 'in', 'himself', 'of', 'o', '@', \"doesn't\", 'being', 'before', 'too', 'will', 'if', 'ain', 'weren', 'yourselves', \"shan't\", '.', 'won', \"aren't\", \"don't\", '&', 't', 'than', 'having', 'very', 'when', 'hasn', 'wasn', '+', '!', 'few', 'll', 'we', 'further', 'have', \"you're\", 'all', 'are', 'didn', 'her', 'd', 'up', 'yourself', 'y', 'doesn', 'isn', 'shan', \"haven't\", 'their', 'through', 'again', '>', 'there', \"it's\", ']', '/', '`', 're', ';', \"wasn't\", 'most', 'mustn', 'couldn', 'above', 'yours', '\"', 'this', 'were', 'ma', '#', 'its', 'that', '?', 'between', 'to', 'did', 'any', 'after', \"you've\", 'wouldn', '<', '\\\\', 'as', 'you', \"she's\", '*', 'she', 'hers', 'no', 'me', '%', \"mightn't\", ')', ':', 'your', 'below', 'once', \"won't\", 'am', \"hasn't\", 'over', 'such', \"weren't\", 'because', 'by', 'but', '_', 'and', 'ours', 'here', 'with', 'some', 'whom', '[', 'out', 'then', 'a', 'doing', 'does', 'for', \"mustn't\", \"that'll\", ',', \"didn't\", 'theirs', '^', 'haven', 'other', 'at', '{', 'off', 'him', 'those', 'needn', 'our', 'each', 'don', \"isn't\", \"'\", 'how', 'only', 'now', 'about', 'them', 'not', 'these', 'so', 'should', '$', 'the', 'shouldn', '=', 'itself', 'both', 'same', 'm', 's', 'it', 'can', \"shouldn't\", 'my', 'is', 'do', 've', \"should've\", 'from', 'themselves', 'an', 'who', \"needn't\", 'just', 'myself', 'during', \"wouldn't\", 'more', 'his', 'herself', 'they', 'which', 'has', 'had', 'i', 'what', 'been'}\n"
     ]
    }
   ],
   "source": [
    "stopwords_en_withpunct = stopwords_en.union(set(punctuation))\n",
    "print(stopwords_en_withpunct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['born', '15th', 'october', '1931', 'rameswaram', 'tamil', 'nadu', 'dr.', 'avul', 'pakir', 'jainulabdeen', 'abdul', 'kalam', 'specialized', 'aeronautical', 'engineering', 'madras', 'institute', 'technology', 'dr.', 'kalam', 'made', 'significant', 'contribution', 'project', 'director', 'develop', 'india', \"'s\", 'first', 'indigenous', 'satellite', 'launch', 'vehicle', 'slv-iii', 'successfully', 'injected', 'rohini', 'satellite', 'near', 'earth', 'orbit', 'july', '1980', 'made', 'india', 'exclusive', 'member', 'space', 'club', 'responsible', 'evolution', 'isro', \"'s\", 'launch', 'vehicle', 'programme', 'particularly', 'pslv', 'configuration', 'working', 'two', 'decades', 'isro', 'mastering', 'launch', 'vehicle', 'technologies', 'dr.', 'kalam', 'took', 'responsibility', 'developing', 'indigenous', 'guided', 'missiles', 'defence', 'research', 'development', 'organisation', 'chief', 'executive', 'integrated', 'guided', 'missile', 'development', 'programme', 'igmdp', 'responsible', 'development', 'operationalisation', 'agni', 'prithvi', 'missiles', 'building', 'indigenous', 'capability', 'critical', 'technologies', 'networking', 'multiple', 'institutions', 'scientific', 'adviser', 'defence', 'minister', 'secretary', 'department']\n"
     ]
    }
   ],
   "source": [
    "print([word for word in single_tokenized_lowered if word not in stopwords_en_withpunct])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "born\n",
      "on\n",
      "15th\n",
      "octob\n",
      "1931\n",
      "at\n",
      "rameswaram\n",
      "in\n",
      "tamil\n",
      "nadu\n",
      ",\n",
      "dr.\n",
      "avul\n",
      "pakir\n",
      "jainulabdeen\n",
      "abdul\n",
      "kalam\n",
      ",\n",
      "special\n",
      "in\n",
      "aeronaut\n",
      "engin\n",
      "from\n",
      "madra\n",
      "institut\n",
      "of\n",
      "technolog\n",
      ".\n",
      "dr.\n",
      "kalam\n",
      "made\n",
      "signific\n",
      "contribut\n",
      "as\n",
      "project\n",
      "director\n",
      "to\n",
      "develop\n",
      "india\n",
      "'s\n",
      "first\n",
      "indigen\n",
      "satellit\n",
      "launch\n",
      "vehicl\n",
      "(\n",
      "slv-iii\n",
      ")\n",
      "which\n",
      "success\n",
      "inject\n",
      "the\n",
      "rohini\n",
      "satellit\n",
      "in\n",
      "the\n",
      "near\n",
      "earth\n",
      "orbit\n",
      "in\n",
      "juli\n",
      "1980\n",
      "and\n",
      "made\n",
      "india\n",
      "an\n",
      "exclus\n",
      "member\n",
      "of\n",
      "space\n",
      "club\n",
      ".\n",
      "he\n",
      "wa\n",
      "respons\n",
      "for\n",
      "the\n",
      "evolut\n",
      "of\n",
      "isro\n",
      "'s\n",
      "launch\n",
      "vehicl\n",
      "programm\n",
      ",\n",
      "particularli\n",
      "the\n",
      "pslv\n",
      "configur\n",
      ".\n",
      "after\n",
      "work\n",
      "for\n",
      "two\n",
      "decad\n",
      "in\n",
      "isro\n",
      "and\n",
      "master\n",
      "launch\n",
      "vehicl\n",
      "technolog\n",
      ",\n",
      "dr.\n",
      "kalam\n",
      "took\n",
      "up\n",
      "the\n",
      "respons\n",
      "of\n",
      "develop\n",
      "indigen\n",
      "guid\n",
      "missil\n",
      "at\n",
      "defenc\n",
      "research\n",
      "and\n",
      "develop\n",
      "organis\n",
      "as\n",
      "the\n",
      "chief\n",
      "execut\n",
      "of\n",
      "integr\n",
      "guid\n",
      "missil\n",
      "develop\n",
      "programm\n",
      "(\n",
      "igmdp\n",
      ")\n",
      ".\n",
      "he\n",
      "wa\n",
      "respons\n",
      "for\n",
      "the\n",
      "develop\n",
      "and\n",
      "operationalis\n",
      "of\n",
      "agni\n",
      "and\n",
      "prithvi\n",
      "missil\n",
      "and\n",
      "for\n",
      "build\n",
      "indigen\n",
      "capabl\n",
      "in\n",
      "critic\n",
      "technolog\n",
      "through\n",
      "network\n",
      "of\n",
      "multipl\n",
      "institut\n",
      ".\n",
      "he\n",
      "wa\n",
      "the\n",
      "scientif\n",
      "advis\n",
      "to\n",
      "defenc\n",
      "minist\n",
      "and\n",
      "secretari\n",
      ",\n",
      "depart\n",
      "of\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "for word in single_tokenized_lowered :\n",
    "    print(porter.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "born\n",
      "on\n",
      "15th\n",
      "october\n",
      "1931\n",
      "at\n",
      "rameswaram\n",
      "in\n",
      "tamil\n",
      "nadu\n",
      ",\n",
      "dr.\n",
      "avul\n",
      "pakir\n",
      "jainulabdeen\n",
      "abdul\n",
      "kalam\n",
      ",\n",
      "specialized\n",
      "in\n",
      "aeronautical\n",
      "engineering\n",
      "from\n",
      "madras\n",
      "institute\n",
      "of\n",
      "technology\n",
      ".\n",
      "dr.\n",
      "kalam\n",
      "made\n",
      "significant\n",
      "contribution\n",
      "a\n",
      "project\n",
      "director\n",
      "to\n",
      "develop\n",
      "india\n",
      "'s\n",
      "first\n",
      "indigenous\n",
      "satellite\n",
      "launch\n",
      "vehicle\n",
      "(\n",
      "slv-iii\n",
      ")\n",
      "which\n",
      "successfully\n",
      "injected\n",
      "the\n",
      "rohini\n",
      "satellite\n",
      "in\n",
      "the\n",
      "near\n",
      "earth\n",
      "orbit\n",
      "in\n",
      "july\n",
      "1980\n",
      "and\n",
      "made\n",
      "india\n",
      "an\n",
      "exclusive\n",
      "member\n",
      "of\n",
      "space\n",
      "club\n",
      ".\n",
      "he\n",
      "wa\n",
      "responsible\n",
      "for\n",
      "the\n",
      "evolution\n",
      "of\n",
      "isro\n",
      "'s\n",
      "launch\n",
      "vehicle\n",
      "programme\n",
      ",\n",
      "particularly\n",
      "the\n",
      "pslv\n",
      "configuration\n",
      ".\n",
      "after\n",
      "working\n",
      "for\n",
      "two\n",
      "decade\n",
      "in\n",
      "isro\n",
      "and\n",
      "mastering\n",
      "launch\n",
      "vehicle\n",
      "technology\n",
      ",\n",
      "dr.\n",
      "kalam\n",
      "took\n",
      "up\n",
      "the\n",
      "responsibility\n",
      "of\n",
      "developing\n",
      "indigenous\n",
      "guided\n",
      "missile\n",
      "at\n",
      "defence\n",
      "research\n",
      "and\n",
      "development\n",
      "organisation\n",
      "a\n",
      "the\n",
      "chief\n",
      "executive\n",
      "of\n",
      "integrated\n",
      "guided\n",
      "missile\n",
      "development\n",
      "programme\n",
      "(\n",
      "igmdp\n",
      ")\n",
      ".\n",
      "he\n",
      "wa\n",
      "responsible\n",
      "for\n",
      "the\n",
      "development\n",
      "and\n",
      "operationalisation\n",
      "of\n",
      "agni\n",
      "and\n",
      "prithvi\n",
      "missile\n",
      "and\n",
      "for\n",
      "building\n",
      "indigenous\n",
      "capability\n",
      "in\n",
      "critical\n",
      "technology\n",
      "through\n",
      "networking\n",
      "of\n",
      "multiple\n",
      "institution\n",
      ".\n",
      "he\n",
      "wa\n",
      "the\n",
      "scientific\n",
      "adviser\n",
      "to\n",
      "defence\n",
      "minister\n",
      "and\n",
      "secretary\n",
      ",\n",
      "department\n",
      "of\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "for word in single_tokenized_lowered:\n",
    "    print(wnl.lemmatize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = '''Born on 15th October 1931 at Rameswaram in Tamil Nadu, \n",
    "Dr. Avul Pakir Jainulabdeen Abdul Kalam, specialized in Aeronautical \n",
    "Engineering from Madras Institute of Technology. Dr. Kalam made\n",
    "significant contribution as Project Director to develop India's \n",
    "first indigenous Satellite Launch Vehicle (SLV-III) which successfully \n",
    "injected the Rohini satellite in the near earth orbit in July 1980 and \n",
    "made India an exclusive member of Space Club. He was responsible for the\n",
    "evolution of ISRO's launch vehicle programme, particularly the PSLV \n",
    "configuration. After working for two decades in ISRO and mastering \n",
    "launch vehicle technologies, Dr. Kalam took up the responsibility \n",
    "of developing Indigenous Guided Missiles at Defence Research and \n",
    "Development Organisation as the Chief Executive of Integrated Guided\n",
    "Missile Development Programme (IGMDP). He was responsible for the development \n",
    "and operationalisation of AGNI and PRITHVI Missiles and for building indigenous\n",
    "capability in critical technologies through networking of multiple institutions. \n",
    "He was the Scientific Adviser to Defence Minister and Secretary, Department of'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Born', 'NNP'), ('15th', 'CD'), ('October', 'NNP'), ('1931', 'CD'), ('Rameswaram', 'NNP'), ('Tamil', 'NNP'), ('Nadu', 'NNP'), (',', ','), ('Dr.', 'NNP'), ('Avul', 'NNP'), ('Pakir', 'NNP'), ('Jainulabdeen', 'NNP'), ('Abdul', 'NNP'), ('Kalam', 'NNP'), (',', ','), ('specialized', 'VBD'), ('Aeronautical', 'NNP'), ('Engineering', 'NNP'), ('Madras', 'NNP'), ('Institute', 'NNP'), ('Technology', 'NNP'), ('.', '.')]\n",
      "[('Dr.', 'NNP'), ('Kalam', 'NNP'), ('made', 'VBD'), ('significant', 'JJ'), ('contribution', 'NN'), ('Project', 'NNP'), ('Director', 'NNP'), ('develop', 'VB'), ('India', 'NNP'), (\"'s\", 'POS'), ('first', 'JJ'), ('indigenous', 'JJ'), ('Satellite', 'NNP'), ('Launch', 'NNP'), ('Vehicle', 'NNP'), ('(', '('), ('SLV-III', 'NNP'), (')', ')'), ('successfully', 'RB'), ('injected', 'VBN'), ('Rohini', 'NNP'), ('satellite', 'NN'), ('near', 'IN'), ('earth', 'JJ'), ('orbit', 'NN'), ('July', 'NNP'), ('1980', 'CD'), ('made', 'VBD'), ('India', 'NNP'), ('exclusive', 'JJ'), ('member', 'NN'), ('Space', 'NNP'), ('Club', 'NNP'), ('.', '.')]\n",
      "[('He', 'PRP'), ('responsible', 'JJ'), ('evolution', 'NN'), ('ISRO', 'NNP'), (\"'s\", 'POS'), ('launch', 'NN'), ('vehicle', 'NN'), ('programme', 'NN'), (',', ','), ('particularly', 'RB'), ('PSLV', 'NNP'), ('configuration', 'NN'), ('.', '.')]\n",
      "[('After', 'IN'), ('working', 'VBG'), ('two', 'CD'), ('decades', 'NNS'), ('ISRO', 'NNP'), ('mastering', 'VBG'), ('launch', 'JJ'), ('vehicle', 'NN'), ('technologies', 'NNS'), (',', ','), ('Dr.', 'NNP'), ('Kalam', 'NNP'), ('took', 'VBD'), ('responsibility', 'NN'), ('developing', 'VBG'), ('Indigenous', 'NNP'), ('Guided', 'NNP'), ('Missiles', 'NNP'), ('Defence', 'NNP'), ('Research', 'NNP'), ('Development', 'NNP'), ('Organisation', 'NNP'), ('Chief', 'NNP'), ('Executive', 'NNP'), ('Integrated', 'NNP'), ('Guided', 'NNP'), ('Missile', 'NNP'), ('Development', 'NNP'), ('Programme', 'NNP'), ('(', '('), ('IGMDP', 'NNP'), (')', ')'), ('.', '.')]\n",
      "[('He', 'PRP'), ('responsible', 'JJ'), ('development', 'NN'), ('operationalisation', 'NN'), ('AGNI', 'NNP'), ('PRITHVI', 'NNP'), ('Missiles', 'NNP'), ('building', 'VBG'), ('indigenous', 'JJ'), ('capability', 'NN'), ('critical', 'JJ'), ('technologies', 'NNS'), ('networking', 'VBG'), ('multiple', 'JJ'), ('institutions', 'NNS'), ('.', '.')]\n",
      "[('He', 'PRP'), ('Scientific', 'NNP'), ('Adviser', 'NNP'), ('Defence', 'NNP'), ('Minister', 'NNP'), ('Secretary', 'NNP'), (',', ','), ('Department', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))  \n",
    "tokenized = sent_tokenize(doc) \n",
    "for i in tokenized: \n",
    "    wordsList = nltk.word_tokenize(i) \n",
    "    wordsList = [w for w in wordsList if not w in stop_words]  \n",
    "    tagged = nltk.pos_tag(wordsList) \n",
    "  \n",
    "    print(tagged) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
